{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import speechbrain as sb\n",
    "import os, sys\n",
    "from speechbrain.utils.data_utils import get_all_files\n",
    "from speechbrain.dataio.dataio import read_audio\n",
    "import json\n",
    "import torchaudio\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_file(path):\n",
    "    \"\"\"\n",
    "    Processes a single audio file to extract its identifier, path, number of speakers, and length.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path of the audio file.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the audio file identifier and a dictionary with metadata about the audio file.\n",
    "             The metadata includes the normalized path, number of speakers, and length in seconds.\n",
    "    \"\"\"\n",
    "    parts = path.split(\"/\")[-1].split(\"\\\\\")[-1].split(\"_\") #.split(\"\\\\\") can be ignored when using a linux based system\n",
    "    id = \"_\".join(parts[:-1])\n",
    "    num_speakers = parts[3]\n",
    "    info = torchaudio.info(path)\n",
    "    length = info.num_frames / 16000\n",
    "\n",
    "    return id, {\n",
    "        \"wav_path\": path.replace(\"\\\\\",\"/\"),  #.split(\"\\\\\") can be ignored when using a linux based system\n",
    "        \"num_speakers\": num_speakers,\n",
    "        \"length\": length\n",
    "    }\n",
    "\n",
    "def load_json(json_paths, save_file=\"train\"):\n",
    "    \"\"\"\n",
    "    Loads multiple audio files, processes each using `process_file`, and saves the metadata in a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    - json_paths (list): A list of paths to audio files to process.\n",
    "    - save_file (str): The base name for the output JSON file where the metadata will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None. This function generates a JSON file in the '../data/' directory containing the metadata for each audio file.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    # Parallel processing\n",
    "    results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(process_file)(path) for path in json_paths\n",
    "    )\n",
    "\n",
    "    for id, path_data in results:\n",
    "        data[id] = path_data\n",
    "\n",
    "    with open(f\"../data/{save_file}_data.json\", 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "train_files = get_all_files(\"../data/train\", match_and=['_segment.wav'])\n",
    "test_files = get_all_files(\"../data/dev\", match_and=['_segment.wav'])\n",
    "valid_files = get_all_files(\"../data/eval\", match_and=['_segment.wav'])\n",
    "\n",
    "load_json(train_files, save_file=\"train\")\n",
    "load_json(test_files, save_file=\"test\")\n",
    "load_json(valid_files, save_file=\"valid\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## XVector Model",
   "id": "ea2b934e3a6d3bdd"
  },
  {
   "cell_type": "code",
   "source": [
    "%%file hparams_selfsupervised_xvector.yaml\n",
    "\n",
    "# Seed for reproducibility of results. Must be set before initializing model components that depend on randomness.\n",
    "seed: 1986\n",
    "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
    "\n",
    "# Paths for saving outputs and logs from the model training process.\n",
    "output_folder: !ref ../results/selfsupervised/Xvector/<seed>\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# SSL (Self-Supervised Learning) Model Configuration\n",
    "# We choose the base model of wav2vec2 which is not fine-tuned to demonstrate the generalizability and potential improvements.\n",
    "sslmodel_hub: facebook/wav2vec2-base\n",
    "sslmodel_folder: !ref <save_folder>/ssl_checkpoint\n",
    "\n",
    "# Directories for storing processed data and annotations.\n",
    "data_folder: ../data  # e.g., /path/to/data\n",
    "train_annotation: !ref <data_folder>/train_data.json\n",
    "valid_annotation: !ref <data_folder>/valid_data.json\n",
    "test_annotation: !ref <data_folder>/test_data.json\n",
    "\n",
    "# Logger for recording training progress and statistics.\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "number_of_epochs: 5\n",
    "batch_size: 32\n",
    "lr: 0.001 # Learning rate for the model optimizer.\n",
    "lr_final: 0.0001 # Final learning rate after annealing.\n",
    "lr_ssl: 0.00001 # Learning rate specific to the SSL model components.\n",
    "\n",
    "# Control the freezing of model layers to fine-tune specific components.\n",
    "freeze_ssl: False # Freeze all layers of the SSL model.\n",
    "freeze_ssl_conv: True # Only freeze convolutional layers of the SSL model for potential performance improvement.\n",
    "\n",
    "####################### Model Parameters #######################################\n",
    "# Dimensions for the encoder and embeddings used within the x-vector architecture.\n",
    "encoder_dim: 768\n",
    "emb_dim: 64\n",
    "out_n_neurons: 5 # Output neurons corresponding to the number of classes in the task.\n",
    "\n",
    "# DataLoader configuration to specify how training data is batched and handled during training.\n",
    "dataloader_options:\n",
    "    batch_size: !ref <batch_size>\n",
    "    shuffle: True\n",
    "    num_workers: 0  # Number of workers for data loading. Use 2 for Linux, 0 for Windows compatibility.\n",
    "    drop_last: False\n",
    "\n",
    "# Configuration for the SSL model loaded from Hugging Face's Transformers library.\n",
    "ssl_model: !new:speechbrain.lobes.models.huggingface_transformers.wav2vec2.Wav2Vec2\n",
    "    source: !ref <sslmodel_hub>\n",
    "    output_norm: True\n",
    "    freeze: !ref <freeze_ssl>\n",
    "    freeze_feature_extractor: !ref <freeze_ssl_conv>\n",
    "    save_path: !ref <sslmodel_folder>\n",
    "\n",
    "# Statistical pooling layer to aggregate model outputs.\n",
    "avg_pool: !new:speechbrain.nnet.pooling.StatisticsPooling\n",
    "    return_std: False\n",
    "\n",
    "# Normalization layer for mean and standard deviation adjustment of input features.\n",
    "mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
    "    norm_type: sentence\n",
    "    std_norm: False\n",
    "\n",
    "# X-vector model configuration for generating embeddings from audio inputs.\n",
    "embedding_model: !new:speechbrain.lobes.models.Xvector.Xvector\n",
    "    in_channels: !ref <encoder_dim>\n",
    "    activation: !name:torch.nn.LeakyReLU\n",
    "    tdnn_blocks: 3\n",
    "    tdnn_channels: [64, 64, 128]\n",
    "    tdnn_kernel_sizes: [5, 2, 1]\n",
    "    tdnn_dilations: [1, 2, 1]\n",
    "    lin_neurons: !ref <emb_dim>\n",
    "\n",
    "# Classifier configuration for predicting output classes from embeddings.\n",
    "classifier: !new:speechbrain.lobes.models.Xvector.Classifier\n",
    "    input_shape: [null, null, !ref <emb_dim>]\n",
    "    activation: !name:torch.nn.LeakyReLU\n",
    "    lin_blocks: 1\n",
    "    lin_neurons: !ref <emb_dim>\n",
    "    out_neurons: !ref <out_n_neurons>\n",
    "\n",
    "# Epoch counter to manage the training cycles.\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <number_of_epochs>\n",
    "\n",
    "# Grouping of modules for training.\n",
    "modules:\n",
    "    ssl_model: !ref <ssl_model>\n",
    "    mean_var_norm: !ref <mean_var_norm>\n",
    "    embedding_model:  !ref <embedding_model>\n",
    "    classifier: !ref <classifier>\n",
    "\n",
    "# Module list grouping for combined optimization.\n",
    "model: !new:torch.nn.ModuleList\n",
    "    - [!ref <embedding_model>, !ref <classifier>]\n",
    "\n",
    "# Log softmax activation for output normalization.\n",
    "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
    "    apply_log: True\n",
    "\n",
    "# Loss function for training.\n",
    "compute_cost: !name:speechbrain.nnet.losses.nll_loss\n",
    "\n",
    "# Metric statistics for evaluating model performance.\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n",
    "\n",
    "# Optimizers for the main model and the SSL components.\n",
    "opt_class: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "ssl_opt_class: !name:torch.optim.Adam\n",
    "    lr: !ref <lr_ssl>\n",
    "\n",
    "# Learning rate schedulers for the main model and SSL model to improve training convergence.\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
    "    initial_value: !ref <lr>\n",
    "    improvement_threshold: 0.0025\n",
    "    annealing_factor: 0.9\n",
    "    patient: 0\n",
    "\n",
    "lr_annealing_ssl: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
    "    initial_value: !ref <lr_ssl>\n",
    "    improvement_threshold: 0.0025\n",
    "    annealing_factor: 0.9\n",
    "\n",
    "# Checkpointing configuration to save and recover training states.\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        model: !ref <model>\n",
    "        ssl_model: !ref <ssl_model>\n",
    "        embedding_model: !ref <embedding_model>\n",
    "        classifier: !ref <classifier>\n",
    "        normalizer: !ref <mean_var_norm>\n",
    "        lr_annealing: !ref <lr_annealing>\n",
    "        lr_annealing_ssl: !ref <lr_annealing_ssl>\n",
    "        counter: !ref <epoch_counter>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6faacf41c41f44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%file selfsupervised_xvector.py\n",
    "import os\n",
    "import sys\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "\n",
    "class SelfSupervisedSpeakerCounter(sb.Brain):\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"\n",
    "        Forward pass for generating predictions from input batches.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (dict): The batch of data to process.\n",
    "        - stage (sb.Stage): The stage of the process (TRAIN, VALID, or TEST).\n",
    "\n",
    "        Returns:\n",
    "        - outputs (Tensor): The output predictions from the classifier.\n",
    "        \"\"\"\n",
    "\n",
    "        batch = batch.to(self.device)\n",
    "        wavs, lens = batch.sig\n",
    "\n",
    "        outputs = self.modules.ssl_model(wavs, lens)\n",
    "        feats = self.modules.mean_var_norm(outputs, lens)\n",
    "        embeddings = self.modules.embedding_model(feats, lens)\n",
    "        outputs = self.modules.classifier(embeddings)\n",
    "        return outputs\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        \"\"\"\n",
    "        Computes the loss for the current batch and stage.\n",
    "\n",
    "        Parameters:\n",
    "        - predictions (Tensor): The predictions made by the model.\n",
    "        - batch (dict): The batch of data including labels.\n",
    "        - stage (sb.Stage): The current stage (TRAIN, VALID, or TEST).\n",
    "\n",
    "        Returns:\n",
    "        - loss (Tensor): The computed loss value.\n",
    "        \"\"\"\n",
    "\n",
    "        spkid, _ = batch.num_speakers_encoded\n",
    "        predictions = predictions.squeeze(1)\n",
    "        spkid = spkid.squeeze(1)\n",
    "\n",
    "        loss = self.hparams.compute_cost(predictions, spkid)\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics.append(batch.id, predictions, spkid)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"\n",
    "        Called at the beginning of each stage to setup metrics and state.\n",
    "\n",
    "        Parameters:\n",
    "        - stage (sb.Stage): The current stage (TRAIN, VALID, or TEST).\n",
    "        - epoch (int, optional): The current epoch number.\n",
    "        \"\"\"\n",
    "\n",
    "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
    "            metric=sb.nnet.losses.nll_loss\n",
    "        )\n",
    "\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
    "        \"\"\"\n",
    "        Called at the end of each stage to summarize and log the stage results.\n",
    "\n",
    "        Parameters:\n",
    "        - stage (sb.Stage): The current stage (TRAIN, VALID, or TEST).\n",
    "        - stage_loss (float): The average loss of the stage.\n",
    "        - epoch (int, optional): The current epoch number, if applicable.\n",
    "        \"\"\"\n",
    "\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "\n",
    "        else:\n",
    "            stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"error_rate\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate adjustments and logging\n",
    "            old_lr, new_lr = self.hparams.lr_annealing(stats[\"error_rate\"])\n",
    "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
    "\n",
    "            (\n",
    "                old_lr_ssl,\n",
    "                new_lr_ssl,\n",
    "            ) = self.hparams.lr_annealing_ssl(stats[\"error_rate\"])\n",
    "            sb.nnet.schedulers.update_learning_rate(\n",
    "                self.ssl_optimizer, new_lr_ssl\n",
    "            )\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch\": epoch, \"lr\": old_lr, \"ssl_lr\": old_lr_ssl},\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats=stats,\n",
    "            )\n",
    "\n",
    "            # Save the current checkpoint and delete previous checkpoints,\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta=stats, min_keys=[\"error_rate\"]\n",
    "            )\n",
    "\n",
    "        # We also write statistics about test data to stdout and to logfile.\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stats,\n",
    "            )\n",
    "\n",
    "    def init_optimizers(self):\n",
    "        \"\"\"\n",
    "        Initializes optimizers for the SSL model and the main model.\n",
    "        \"\"\"\n",
    "        self.ssl_optimizer = self.hparams.ssl_opt_class(\n",
    "            self.modules.ssl_model.parameters()\n",
    "        )\n",
    "        self.optimizer = self.hparams.opt_class(self.hparams.model.parameters())\n",
    "\n",
    "        if self.checkpointer is not None:\n",
    "            self.checkpointer.add_recoverable(\n",
    "                \"ssl_opt\", self.ssl_optimizer\n",
    "            )\n",
    "            self.checkpointer.add_recoverable(\"optimizer\", self.optimizer)\n",
    "\n",
    "        self.optimizers_dict = {\n",
    "            \"model_optimizer\": self.optimizer,\n",
    "            \"ssl_optimizer\": self.ssl_optimizer,\n",
    "        }\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"\n",
    "    Prepares and returns datasets for training, validation, and testing.\n",
    "    Parameters:\n",
    "    - hparams (dict): A dictionary of hyperparameters for data preparation.\n",
    "    Returns:\n",
    "    - datasets (dict): A dictionary containing 'train', 'valid', and 'test' datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define audio pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"wav_path\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav_path):\n",
    "        \"\"\"\n",
    "        Audio processing pipeline that loads and returns an audio signal.\n",
    "        Parameters:\n",
    "            - wav_path (str): Path to the audio file.\n",
    "        Returns:\n",
    "            - sig (Tensor): Loaded audio signal tensor.\n",
    "        \"\"\"\n",
    "        sig = sb.dataio.dataio.read_audio(wav_path)\n",
    "        return sig\n",
    "    \n",
    "    # Initialization of the label encoder.\n",
    "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
    "\n",
    "    # Define label pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"num_speakers\")\n",
    "    @sb.utils.data_pipeline.provides(\"num_speakers\", \"num_speakers_encoded\")\n",
    "    def label_pipeline(num_speakers):\n",
    "        \"\"\"\n",
    "        Processes and encodes the number of speakers.\n",
    "\n",
    "        Parameters:\n",
    "        - num_speakers (int): The number of speakers in the audio.\n",
    "\n",
    "        Yields:\n",
    "        - num_speakers (int): The original number of speakers.\n",
    "        - num_speakers_encoded (Tensor): Encoded tensor of the number of speakers.\n",
    "        \"\"\"\n",
    "\n",
    "        yield num_speakers\n",
    "        num_speakers_encoded = label_encoder.encode_label_torch(num_speakers)\n",
    "        yield num_speakers_encoded\n",
    "\n",
    "    datasets = {}\n",
    "    data_info = {\n",
    "        \"train\": hparams[\"train_annotation\"],\n",
    "        \"valid\": hparams[\"valid_annotation\"],\n",
    "        \"test\": hparams[\"test_annotation\"],\n",
    "        \"test_annotation_0_spk\": hparams[\"test_annotation_0_spk\"],\n",
    "        \"test_annotation_1_spk\": hparams[\"test_annotation_1_spk\"],\n",
    "        \"test_annotation_2_spk\": hparams[\"test_annotation_2_spk\"],\n",
    "        \"test_annotation_3_spk\": hparams[\"test_annotation_3_spk\"],\n",
    "        \"test_annotation_4_spk\": hparams[\"test_annotation_4_spk\"],\n",
    "    }\n",
    "    for dataset in data_info:\n",
    "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
    "            json_path=data_info[dataset],\n",
    "            replacements={\"data_root\": hparams[\"data_folder\"]},\n",
    "            dynamic_items=[audio_pipeline, label_pipeline],\n",
    "            output_keys=[\"id\", \"sig\", \"num_speakers_encoded\"],\n",
    "        )\n",
    "        \n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[datasets[\"train\"]],\n",
    "        output_key=\"num_speakers\",\n",
    "    )\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "# RECIPE BEGINS!\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Reading command line arguments.\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "\n",
    "    # Load hyperparameters file with command-line overrides.\n",
    "    with open(hparams_file) as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Create dataset objects \"train\", \"valid\", and \"test\".\n",
    "    datasets = dataio_prep(hparams)\n",
    "\n",
    "    hparams[\"ssl_model\"] = hparams[\"ssl_model\"].to(device=run_opts[\"device\"])\n",
    "    # freeze the feature extractor part when unfreezing\n",
    "    if not hparams[\"freeze_ssl\"] and hparams[\"freeze_ssl_conv\"]:\n",
    "        hparams[\"ssl_model\"].model.feature_extractor._freeze_parameters()\n",
    "\n",
    "    # Initialize the Brain object to prepare for mask training.\n",
    "    spkcounter = SelfSupervisedSpeakerCounter(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"opt_class\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "    spkcounter.fit(\n",
    "        epoch_counter=spkcounter.hparams.epoch_counter,\n",
    "        train_set=datasets[\"train\"],\n",
    "        valid_set=datasets[\"valid\"],\n",
    "        train_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    )\n",
    "\n",
    "    test_stats = spkcounter.evaluate(\n",
    "        test_set=datasets[\"test\"],\n",
    "        min_key=\"error_rate\",\n",
    "        test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    )\n",
    "    \"\"\"\n",
    "    To get test accuracy on each class uncomment the code below.\n",
    "    \"\"\"\n",
    "    # print(\"Evaluating on no spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_0_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    #\n",
    "    # print(\"Evaluating on 1 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_1_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    #\n",
    "    # print(\"Evaluating on 2 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_2_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    #\n",
    "    # print(\"Evaluating on 3 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_3_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    #\n",
    "    # print(\"Evaluating on 4 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_4_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1e724b1ce923fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.set_device(\"cuda:0\")\n",
    "!python selfsupervised_xvector.py hparams_selfsupervised_xvector.yaml"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1c0c804a085e7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "db7defc4d9d2318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Classifier",
   "id": "ff7703185cd6bc42"
  },
  {
   "cell_type": "code",
   "source": [
    "%%file hparams_selfsupervised_mlp.yaml\n",
    "\n",
    "# Seed for reproducibility of results. Must be set before initializing model components that depend on randomness.\n",
    "seed: 1993\n",
    "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
    "\n",
    "# Paths for saving outputs and logs from the model training process.\n",
    "data_folder: ../data  # e.g., /path/to/data\n",
    "output_folder: !ref ../results/train_with_wav2vec2/<seed>\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# SSL (Self-Supervised Learning) Model Configuration\n",
    "# We choose the base model of wav2vec2 which is not fine-tuned to demonstrate the generalizability and potential improvements.\n",
    "sslmodel_hub: facebook/wav2vec2-base\n",
    "sslmodel_folder: !ref <save_folder>/ssl_checkpoint\n",
    "\n",
    "# Directories for storing processed data and annotations.\n",
    "train_annotation: !ref <data_folder>/train_data.json\n",
    "valid_annotation: !ref <data_folder>/valid_data.json\n",
    "test_annotation: !ref <data_folder>/test_data.json\n",
    "test_annotation_0_spk: !ref <data_folder>/test_files_no_spk_data.json\n",
    "test_annotation_1_spk: !ref <data_folder>/test_files_1_spk_data.json\n",
    "test_annotation_2_spk: !ref <data_folder>/test_files_2_spk_data.json\n",
    "test_annotation_3_spk: !ref <data_folder>/test_files_3_spk_data.json\n",
    "test_annotation_4_spk: !ref <data_folder>/test_files_4_spk_data.json\n",
    "\n",
    "\n",
    "# Logger for recording training progress and statistics.\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "number_of_epochs: 5\n",
    "batch_size: 64\n",
    "lr: 0.001 # Learning rate for the model optimizer.\n",
    "lr_ssl: 0.0001 # Learning rate specific to the SSL model components.\n",
    "\n",
    "# Control the freezing of model layers to fine-tune specific components.\n",
    "freeze_ssl: False # Freeze all layers of the SSL model.\n",
    "freeze_ssl_conv: True # Only freeze convolutional layers of the SSL model for potential performance improvement.\n",
    "\n",
    "####################### Model Parameters #######################################\n",
    "# Dimensions for the encoder and embeddings used within the x-vector architecture.\n",
    "encoder_dim: 768\n",
    "out_n_neurons: 5\n",
    "\n",
    "# DataLoader configuration to specify how training data is batched and handled during training.\n",
    "dataloader_options:\n",
    "    batch_size: !ref <batch_size>\n",
    "    shuffle: True\n",
    "    num_workers: 0  # Number of workers for data loading. Use 2 for Linux, 0 for Windows compatibility.\n",
    "    drop_last: False\n",
    "\n",
    "# Configuration for the SSL model loaded from Hugging Face's Transformers library.\n",
    "ssl_model: !new:speechbrain.lobes.models.huggingface_transformers.wav2vec2.Wav2Vec2\n",
    "    source: !ref <sslmodel_hub>\n",
    "    output_norm: True\n",
    "    freeze: !ref <freeze_ssl>\n",
    "    freeze_feature_extractor: !ref <freeze_ssl_conv>\n",
    "    save_path: !ref <sslmodel_folder>\n",
    "\n",
    "# Statistical pooling layer to aggregate model outputs.\n",
    "avg_pool: !new:speechbrain.nnet.pooling.StatisticsPooling\n",
    "    return_std: False\n",
    "\n",
    "output_mlp: !new:speechbrain.nnet.linear.Linear\n",
    "    input_size: !ref <encoder_dim>\n",
    "    n_neurons: !ref <out_n_neurons>\n",
    "    bias: False\n",
    "\n",
    "# Epoch counter to manage the training cycles.\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <number_of_epochs>\n",
    "\n",
    "# Grouping of modules for training.\n",
    "modules:\n",
    "    ssl_model: !ref <ssl_model>\n",
    "    output_mlp: !ref <output_mlp>\n",
    "\n",
    "# Module list grouping for combined optimization.\n",
    "model: !new:torch.nn.ModuleList\n",
    "    - [!ref <output_mlp>]\n",
    "    -\n",
    "# Log softmax activation for output normalization.\n",
    "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
    "    apply_log: True\n",
    "\n",
    "# Loss function for training.\n",
    "compute_cost: !name:speechbrain.nnet.losses.nll_loss\n",
    "\n",
    "# Metric statistics for evaluating model performance.\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n",
    "\n",
    "# Optimizers for the main model and the SSL components.\n",
    "opt_class: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "\n",
    "ssl_opt_class: !name:torch.optim.Adam\n",
    "    lr: !ref <lr_ssl>\n",
    "\n",
    "# Learning rate schedulers for the main model and SSL model to improve training convergence.\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
    "    initial_value: !ref <lr>\n",
    "    improvement_threshold: 0.0025\n",
    "    annealing_factor: 0.9\n",
    "    patient: 0\n",
    "\n",
    "lr_annealing_ssl: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
    "    initial_value: !ref <lr_ssl>\n",
    "    improvement_threshold: 0.0025\n",
    "    annealing_factor: 0.9\n",
    "\n",
    "# Checkpointing configuration to save and recover training states.\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        model: !ref <model>\n",
    "        ssl_model: !ref <ssl_model>\n",
    "        lr_annealing_output: !ref <lr_annealing>\n",
    "        lr_annealing_ssl: !ref <lr_annealing_ssl>\n",
    "        counter: !ref <epoch_counter>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f44f4594204593f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%file selfsupervised_mlp.py\n",
    "import os\n",
    "import sys\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "\n",
    "class SelfSupervisedSpeakerCounter(sb.Brain):\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"\n",
    "        Forward pass for generating predictions from input batches.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (dict): The batch of data to process.\n",
    "        - stage (sb.Stage): The stage of the process (TRAIN, VALID, or TEST).\n",
    "\n",
    "        Returns:\n",
    "        - outputs (Tensor): The output predictions from the classifier.\n",
    "        \"\"\"\n",
    "        batch = batch.to(self.device)\n",
    "        wavs, lens = batch.sig\n",
    "\n",
    "        outputs = self.modules.ssl_model(wavs, lens)\n",
    "        outputs = self.hparams.avg_pool(outputs, lens)\n",
    "        outputs = outputs.view(outputs.shape[0], -1)\n",
    "\n",
    "        outputs = self.modules.output_mlp(outputs)\n",
    "        outputs = self.hparams.log_softmax(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        \"\"\"\n",
    "        Computes the loss for the current batch and stage.\n",
    "\n",
    "        Parameters:\n",
    "        - predictions (Tensor): The predictions made by the model.\n",
    "        - batch (dict): The batch of data including labels.\n",
    "        - stage (sb.Stage): The current stage (TRAIN, VALID, or TEST).\n",
    "\n",
    "        Returns:\n",
    "        - loss (Tensor): The computed loss value.\n",
    "        \"\"\"\n",
    "\n",
    "        spkid, _ = batch.num_speakers_encoded\n",
    "\n",
    "        \"\"\"to meet the input form of nll loss\"\"\"\n",
    "        spkid = spkid.squeeze(1)\n",
    "        loss = self.hparams.compute_cost(predictions, spkid)\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics.append(batch.id, predictions, spkid)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"\n",
    "        Called at the beginning of each stage to setup metrics and state.\n",
    "\n",
    "        Parameters:\n",
    "        - stage (sb.Stage): The current stage (TRAIN, VALID, or TEST).\n",
    "        - epoch (int, optional): The current epoch number.\n",
    "        \"\"\"\n",
    "\n",
    "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
    "            metric=sb.nnet.losses.nll_loss\n",
    "        )\n",
    "\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
    "        \"\"\"\n",
    "        Called at the end of each stage to summarize and log the stage results.\n",
    "\n",
    "        Parameters:\n",
    "        - stage (sb.Stage): The current stage (TRAIN, VALID, or TEST).\n",
    "        - stage_loss (float): The average loss of the stage.\n",
    "        - epoch (int, optional): The current epoch number, if applicable.\n",
    "        \"\"\"\n",
    "\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "\n",
    "        else:\n",
    "            stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"error_rate\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate adjustments and logging\n",
    "            old_lr, new_lr = self.hparams.lr_annealing(stats[\"error_rate\"])\n",
    "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
    "\n",
    "            (\n",
    "                old_lr_ssl,\n",
    "                new_lr_ssl,\n",
    "            ) = self.hparams.lr_annealing_ssl(stats[\"error_rate\"])\n",
    "            sb.nnet.schedulers.update_learning_rate(\n",
    "                self.ssl_optimizer, new_lr_ssl\n",
    "            )\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch\": epoch, \"lr\": old_lr, \"ssl_lr\": old_lr_ssl},\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats=stats,\n",
    "            )\n",
    "\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta=stats, min_keys=[\"error_rate\"]\n",
    "            )\n",
    "\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stats,\n",
    "            )\n",
    "\n",
    "    def init_optimizers(self):\n",
    "        \"\"\"\n",
    "        Initializes optimizers for the SSL model and the main model.\n",
    "        \"\"\"\n",
    "        self.ssl_optimizer = self.hparams.ssl_opt_class(\n",
    "            self.modules.ssl_model.parameters()\n",
    "        )\n",
    "        self.optimizer = self.hparams.opt_class(self.hparams.model.parameters())\n",
    "\n",
    "        if self.checkpointer is not None:\n",
    "            self.checkpointer.add_recoverable(\n",
    "                \"ssl_opt\", self.ssl_optimizer\n",
    "            )\n",
    "            self.checkpointer.add_recoverable(\"optimizer\", self.optimizer)\n",
    "\n",
    "        self.optimizers_dict = {\n",
    "            \"model_optimizer\": self.optimizer,\n",
    "            \"ssl_optimizer\": self.ssl_optimizer,\n",
    "        }\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"\n",
    "    Prepares and returns datasets for training, validation, and testing.\n",
    "    Parameters:\n",
    "    - hparams (dict): A dictionary of hyperparameters for data preparation.\n",
    "    Returns:\n",
    "    - datasets (dict): A dictionary containing 'train', 'valid', and 'test' datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define audio pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"wav_path\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav_path):\n",
    "        \"\"\"\n",
    "        Audio processing pipeline that loads and returns an audio signal.\n",
    "        Parameters:\n",
    "            - wav_path (str): Path to the audio file.\n",
    "        Returns:\n",
    "            - sig (Tensor): Loaded audio signal tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        sig = sb.dataio.dataio.read_audio(wav_path)\n",
    "        return sig\n",
    "\n",
    "    # Label Encoder\n",
    "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
    "\n",
    "    # Define label pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"num_speakers\")\n",
    "    @sb.utils.data_pipeline.provides(\"num_speakers\", \"num_speakers_encoded\")\n",
    "    def label_pipeline(num_speakers):\n",
    "        \"\"\"\n",
    "        Processes and encodes the number of speakers.\n",
    "        Parameters:\n",
    "             - num_speakers (int): The number of speakers in the audio.\n",
    "        Yields:\n",
    "            - num_speakers (int): The original number of speakers.\n",
    "            - num_speakers_encoded (Tensor): Encoded tensor of the number of speakers.\n",
    "        \"\"\"\n",
    "        yield num_speakers\n",
    "        num_speakers_encoded = label_encoder.encode_label_torch(num_speakers)\n",
    "        yield num_speakers_encoded\n",
    "\n",
    "    datasets = {}\n",
    "    data_info = {\n",
    "        \"train\": hparams[\"train_annotation\"],\n",
    "        \"valid\": hparams[\"valid_annotation\"],\n",
    "        # \"test\": hparams[\"test_annotation\"],\n",
    "        \"test_annotation_0_spk\": hparams[\"test_annotation_0_spk\"],\n",
    "        \"test_annotation_1_spk\": hparams[\"test_annotation_1_spk\"],\n",
    "        \"test_annotation_2_spk\": hparams[\"test_annotation_2_spk\"],\n",
    "        \"test_annotation_3_spk\": hparams[\"test_annotation_3_spk\"],\n",
    "        \"test_annotation_4_spk\": hparams[\"test_annotation_4_spk\"],\n",
    "    }\n",
    "    for dataset in data_info:\n",
    "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
    "            json_path=data_info[dataset],\n",
    "            replacements={\"data_root\": hparams[\"data_folder\"]},\n",
    "            dynamic_items=[audio_pipeline, label_pipeline],\n",
    "            output_keys=[\"id\", \"sig\", \"num_speakers_encoded\"],\n",
    "        )\n",
    "\n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[datasets[\"train\"]],\n",
    "        output_key=\"num_speakers\",\n",
    "    )\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "# RECIPE BEGINS!\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Reading command line arguments.\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "\n",
    "    # Load hyperparameters file with command-line overrides.\n",
    "    with open(hparams_file) as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Create dataset objects \"train\", \"valid\", and \"test\".\n",
    "    datasets = dataio_prep(hparams)\n",
    "\n",
    "    hparams[\"ssl_model\"] = hparams[\"ssl_model\"].to(device=run_opts[\"device\"])\n",
    "    # freeze the feature extractor part when unfreezing\n",
    "    if not hparams[\"freeze_ssl\"] and hparams[\"freeze_ssl_conv\"]:\n",
    "        hparams[\"ssl_model\"].model.feature_extractor._freeze_parameters()\n",
    "\n",
    "    # Initialize the Brain object to prepare for mask training.\n",
    "    spkcounter = SelfSupervisedSpeakerCounter(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"opt_class\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "    spkcounter.fit(\n",
    "        epoch_counter=spkcounter.hparams.epoch_counter,\n",
    "        train_set=datasets[\"train\"],\n",
    "        valid_set=datasets[\"valid\"],\n",
    "        train_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    )\n",
    "\n",
    "    # Load the best checkpoint for evaluation\n",
    "    print(\"Evaluating on all classes\")\n",
    "    test_stats = spkcounter.evaluate(\n",
    "        test_set=datasets[\"test\"],\n",
    "        min_key=\"error_rate\",\n",
    "        test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    To get test accuracy on each class uncomment the code below.\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"Evaluating on no spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_0_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    # \n",
    "    # print(\"Evaluating on 1 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_1_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    # \n",
    "    # print(\"Evaluating on 2 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_2_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    # \n",
    "    # print(\"Evaluating on 3 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_3_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )\n",
    "    # \n",
    "    # print(\"Evaluating on 4 spk class\")\n",
    "    # test_stats = spkcounter.evaluate(\n",
    "    #     test_set=datasets[\"test_annotation_4_spk\"],\n",
    "    #     min_key=\"error_rate\",\n",
    "    #     test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    # )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26c6b8ad8fdb0883",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.set_device(\"cuda:0\")\n",
    "!python selfsupervised_mlp.py hparams_selfsupervised_mlp.yaml"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f44f290b6b4881f4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
