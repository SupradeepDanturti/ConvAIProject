{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPw9gtGo3CNOy2oYBsocFjc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupradeepDanturti/ConvAIProject/blob/main/sample_run_tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B-KSPbh3dtzM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install speechbrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir  /content/maindata\n",
        "!mkdir  /content/maindata/train\n",
        "!mkdir  /content/maindata/dev\n",
        "!mkdir  /content/maindata/eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUtdKCTqd0HT",
        "outputId": "8d695761-c0d4-492d-be13-d931ffb8179e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/maindata/train’: File exists\n",
            "mkdir: cannot create directory ‘/content/maindata/dev’: File exists\n",
            "mkdir: cannot create directory ‘/content/maindata/eval’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!unzip /content/drive/MyDrive/ConvAI/Project/sample_set.zip"
      ],
      "metadata": {
        "id": "dYZXIFPIhkh3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "import json\n",
        "import speechbrain as sb\n",
        "import os, sys\n",
        "from speechbrain.utils.data_utils import get_all_files\n",
        "import torch\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "import random\n",
        "import torchaudio\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torchaudio\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "def process_file(path):\n",
        "    # Optimized path operations\n",
        "    parts = path.split(\"/\")[-1].split(\"\\\\\")[-1].split(\"_\")\n",
        "    id = \"_\".join(parts[:-1])\n",
        "    num_speakers = parts[3]\n",
        "    info = torchaudio.info(path)\n",
        "    length = info.num_frames / 16000\n",
        "\n",
        "    return id, {\n",
        "        \"wav_path\": path.replace(\"\\\\\",\"/\"),\n",
        "        \"num_speakers\": num_speakers,\n",
        "        \"length\": length\n",
        "    }\n",
        "\n",
        "def load_json(json_paths, save_file=\"train\"):\n",
        "    data = {}\n",
        "\n",
        "    # Parallel processing\n",
        "    results = Parallel(n_jobs=-1, verbose=10)(\n",
        "        delayed(process_file)(path) for path in json_paths\n",
        "    )\n",
        "\n",
        "    for id, path_data in results:\n",
        "        data[id] = path_data\n",
        "\n",
        "    with open(f\"/content/{save_file}_data.json\", 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "train_files = get_all_files(\"/content/train\", match_and=['_segment.wav'])\n",
        "test_files = get_all_files(\"/content/dev\", match_and=['_segment.wav'])\n",
        "valid_files = get_all_files(\"/content/eval\", match_and=['_segment.wav'])\n",
        "\n",
        "load_json(train_files, save_file=\"train\")\n",
        "load_json(test_files, save_file=\"test\")\n",
        "load_json(valid_files, save_file=\"valid\")\n"
      ],
      "metadata": {
        "id": "NwbgnUMWgwgw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hparams_xvector_fbanks.yaml\n",
        "\n",
        "\n",
        "\n",
        "# Your code here\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 1986\n",
        "__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "output_folder: !ref /content/results/TIMIT_tiny/Xvector/FBanks/<seed>\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "\n",
        "# Path where data manifest files are stored\n",
        "data_dir: /content\n",
        "train_annotation: !ref <data_dir>/train_data.json\n",
        "valid_annotation: !ref <data_dir>/valid_data.json\n",
        "test_annotation: !ref <data_dir>/test_data.json\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
        "    metric: !name:speechbrain.nnet.losses.classification_error\n",
        "        reduction: batch\n",
        "\n",
        "# Logging tensorboard\n",
        "use_tensorboard: True\n",
        "tensorboard_logs: /content/logs\n",
        "\n",
        "tensorboard_train_logger: !new:speechbrain.utils.train_logger.TensorboardLogger\n",
        "    save_dir: !ref <tensorboard_logs>\n",
        "\n",
        "# Feature parameters\n",
        "n_mels: 40\n",
        "deltas: True\n",
        "\n",
        "# Training Parameters\n",
        "sample_rate: 16000\n",
        "number_of_epochs: 2\n",
        "batch_size: 64\n",
        "# lr_start: 0.001\n",
        "# lr_final: 0.0001\n",
        "# lr_dont_halve_until_epoch: 80\n",
        "# lr_patience: 1\n",
        "n_classes: 5\n",
        "emb_dim: 64 # dimensionality of the embeddings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataloader_options:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Feature extraction\n",
        "compute_features: !new:speechbrain.lobes.features.Fbank\n",
        "    n_mels: !ref <n_mels>\n",
        "    # deltas: !ref <deltas>\n",
        "\n",
        "# Mean and std normalization of the input features\n",
        "mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
        "    norm_type: global\n",
        "\n",
        "# Embedding model: from variable size digits gets a fixed size embedding vector\n",
        "embedding_model: !new:speechbrain.lobes.models.Xvector.Xvector\n",
        "    in_channels: !ref <n_mels>\n",
        "    activation: !name:torch.nn.LeakyReLU\n",
        "    tdnn_blocks: 5\n",
        "    tdnn_channels: [64, 64, 64, 64, 512]\n",
        "    tdnn_kernel_sizes: [5, 3, 3, 1, 1]\n",
        "    tdnn_dilations: [1, 2, 3, 1, 1]\n",
        "    lin_neurons: !ref <emb_dim>\n",
        "\n",
        "# Clasifier applied on top of the embeddings\n",
        "classifier: !new:speechbrain.lobes.models.Xvector.Classifier\n",
        "    input_shape: [null, null, !ref <emb_dim>]\n",
        "    activation: !name:torch.nn.LeakyReLU\n",
        "    lin_blocks: 1\n",
        "    lin_neurons: !ref <emb_dim>\n",
        "    out_neurons: !ref <n_classes>\n",
        "\n",
        "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
        "# which is saved by the Checkpointer so that training can be resumed\n",
        "# if it gets interrupted at any point.\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
        "# device, as well as having train()/eval() called on them by the Brain class.\n",
        "modules:\n",
        "    compute_features: !ref <compute_features>\n",
        "    mean_var_norm: !ref <mean_var_norm>\n",
        "    embedding_model: !ref <embedding_model>\n",
        "    classifier: !ref <classifier>\n",
        "\n",
        "# This optimizer will be constructed by the Brain class after all parameters\n",
        "# are moved to the correct device. Then it will be added to the checkpointer.\n",
        "#\n",
        "# opt_class: !name:torch.optim.Adadelta\n",
        "#     lr: !ref <lr>\n",
        "#     rho: 0.95\n",
        "#     eps: 1.e-8\n",
        "\n",
        "\n",
        "opt_class: !name:torch.optim.Adam\n",
        "    lr: 0.001\n",
        "    weight_decay: 0.00002\n",
        "\n",
        "# This function manages learning rate annealing over the epochs.\n",
        "# We here use the simple lr annealing method that linearly decreases\n",
        "# the lr from the initial value to the final one.\n",
        "\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
        "    mode: triangular2\n",
        "    gamma: 0.9998\n",
        "    base_lr: 0.001 #best for adam\n",
        "    max_lr: 0.004 #hope that it escapes local minima\n",
        "    step_size: 9935 #317920/64 = 4967.5 *2-8 == 9935-39740\n",
        "\n",
        "\n",
        "\n",
        "# lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
        "#    initial_value: !ref <lr_start>\n",
        "#    final_value: !ref <lr_final>\n",
        "#    epoch_count: !ref <number_of_epochs>\n",
        "\n",
        "#\n",
        "# lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
        "#     initial_value: !ref <lr>\n",
        "#     improvement_threshold: 0.0025\n",
        "#     annealing_factor: 0.8\n",
        "#     patient: 0\n",
        "\n",
        "# lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
        "#     lr_min: !ref <lr_final>\n",
        "#     dont_halve_until_epoch: !ref <lr_dont_halve_until_epoch>\n",
        "#     patience: !ref <lr_patience>\n",
        "\n",
        "# lr_annealing_model_3: !new:speechbrain.nnet.schedulers.CyclicCosineScheduler\n",
        "#   lr_initial: !ref <peak_lr>\n",
        "#   n_warmup_steps: !ref <warmup_steps>\n",
        "#   total_steps: !ref <total_step>\n",
        "\n",
        "\n",
        "\n",
        "# This object is used for saving the state of training both so that it\n",
        "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
        "# can be later loaded for evaluation or inference.\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        embedding_model: !ref <embedding_model>\n",
        "        classifier: !ref <classifier>\n",
        "        normalizer: !ref <mean_var_norm>\n",
        "        counter: !ref <epoch_counter>\n",
        "        lr_annealing: !ref <lr_annealing>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piLSA1ZReJcS",
        "outputId": "505ab4e4-0ce5-4c45-d237-b501316d0e2d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hparams_xvector_fbanks.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train.py\n",
        "# Your code here\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "\"Recipe for training a spk classification system.\"\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torchaudio\n",
        "import speechbrain as sb\n",
        "import speechbrain.nnet.schedulers as schedulers\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from speechbrain.utils.train_logger import TensorboardLogger\n",
        "\n",
        "\n",
        "\n",
        "# Brain class for speech enhancement training\n",
        "class DigitBrain(sb.Brain):\n",
        "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Runs all the computations that transforms the input into the\n",
        "        output probabilities over the N classes.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "        Returns\n",
        "        -------\n",
        "        predictions : Tensor\n",
        "            Tensor that contains the posterior probabilities over the N classes.\n",
        "        \"\"\"\n",
        "        # Your code here. Aim for 7-8 lines\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, lens = batch.sig\n",
        "        feats = self.modules.compute_features(wavs)\n",
        "        feats = self.modules.mean_var_norm(feats, lens)\n",
        "        embeddings = self.modules.embedding_model(feats, lens)\n",
        "        predictions = self.modules.classifier(embeddings)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        predictions : tensor\n",
        "            The output tensor from `compute_forward`.\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            A one-element tensor used for backpropagating the gradient.\n",
        "        \"\"\"\n",
        "\n",
        "        # Your code here. Aim for 7-8 lines\n",
        "        _, lens = batch['sig']\n",
        "        num_speakers_encoded = batch[\"num_speakers_encoded\"].data\n",
        "\n",
        "        loss = sb.nnet.losses.nll_loss(predictions, num_speakers_encoded, lens)\n",
        "        self.loss_metric.append(\n",
        "            batch.id, predictions, num_speakers_encoded, lens, reduction=\"batch\"\n",
        "        )\n",
        "\n",
        "        # Compute classification error at test time\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            if hasattr(self.hparams.lr_annealing, \"on_batch_end\"):\n",
        "                self.hparams.lr_annealing.on_batch_end(self.optimizer)\n",
        "\n",
        "            self.error_metrics.append(batch.id, predictions, num_speakers_encoded, lens)\n",
        "        return loss\n",
        "\n",
        "    def on_stage_start(self, stage, epoch=None):\n",
        "        \"\"\"Gets called at the beginning of each epoch.\n",
        "        Arguments\n",
        "        ---------\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "        epoch : int\n",
        "            The currently-starting epoch. This is passed\n",
        "            `None` during the test stage.\n",
        "        \"\"\"\n",
        "\n",
        "        # Set up statistics trackers for this stage\n",
        "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
        "            metric=sb.nnet.losses.nll_loss\n",
        "        )\n",
        "\n",
        "        # Set up evaluation-only statistics trackers\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.error_metrics = self.hparams.error_stats()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
        "        \"\"\"Gets called at the end of an epoch.\n",
        "        Arguments\n",
        "        ---------\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
        "        stage_loss : float\n",
        "            The average loss for all of the data processed in this stage.\n",
        "        epoch : int\n",
        "            The currently-starting epoch. This is passed\n",
        "            `None` during the test stage.\n",
        "        \"\"\"\n",
        "\n",
        "        # Store the train loss until the validation stage.\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_loss = stage_loss\n",
        "\n",
        "        # Summarize the statistics from the stage for record-keeping.\n",
        "        else:\n",
        "            stats = {\n",
        "                \"loss\": stage_loss,\n",
        "                \"error\": self.error_metrics.summarize(\"average\"),\n",
        "            }\n",
        "\n",
        "        # At the end of validation...\n",
        "        if stage == sb.Stage.VALID:\n",
        "            # if isinstance(\n",
        "            #     self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
        "            # ):\n",
        "            #     current_lr, next_lr = self.hparams.lr_scheduler(\n",
        "            #         [self.optimizer], epoch, stage_loss\n",
        "            #     )\n",
        "            #     sb.nnet.schedulers.update_learning_rate(self.optimizer, next_lr)\n",
        "            # elif isinstance(\n",
        "            #         self.hparams.lr_annealing,\n",
        "            #         sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "            #     ):\n",
        "            #     current_lr, next_lr = self.hparams.lr_annealing(stage_loss)\n",
        "            #     sb.nnet.schedulers.update_learning_rate(self.optimizer, next_lr)\n",
        "            #\n",
        "            # else:\n",
        "            #     current_lr, next_lr = self.hparams.lr_annealing(epoch)\n",
        "            #     sb.nnet.schedulers.update_learning_rate(self.optimizer, next_lr)\n",
        "\n",
        "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
        "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "\n",
        "            # The train_logger writes a summary to stdout and to the logfile.\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats={\"loss\": stage_loss},\n",
        "                valid_stats=stats,\n",
        "            )\n",
        "\n",
        "            # Save the current checkpoint and delete previous checkpoints,\n",
        "            self.checkpointer.save_and_keep_only(meta=stats, min_keys=[\"error\"])\n",
        "\n",
        "            if self.hparams.use_tensorboard:\n",
        "                valid_stats = {\n",
        "                \"loss\": stage_loss,\n",
        "                \"error\": self.error_metrics.summarize(\"average\"),\n",
        "                }\n",
        "                self.hparams.tensorboard_train_logger.log_stats(valid_stats)\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch\": epoch},\n",
        "                train_stats={\"loss\": self.train_loss},\n",
        "                valid_stats=stats,\n",
        "            )\n",
        "\n",
        "        # We also write statistics about test data to stdout and to the logfile.\n",
        "        if stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stats,\n",
        "            )\n",
        "\n",
        "\n",
        "def dataio_prep(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "    We expect `prepare_mini_librispeech` to have been called before this,\n",
        "    so that the `train.json`, `valid.json`,  and `valid.json` manifest files\n",
        "    are available.\n",
        "    Arguments\n",
        "    ---------\n",
        "    hparams : dict\n",
        "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
        "        all the hyperparameters needed for dataset construction and loading.\n",
        "    Returns\n",
        "    -------\n",
        "    datasets : dict\n",
        "        Contains two keys, \"train\" and \"valid\" that correspond\n",
        "        to the appropriate DynamicItemDataset object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialization of the label encoder. The label encoder assigns to each\n",
        "    # of the observed label a unique index (e.g, 'digit0': 0, 'digit1': 1, ..)\n",
        "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
        "    print(label_encoder)\n",
        "\n",
        "    # Define audio pipeline\n",
        "    @sb.utils.data_pipeline.takes(\"wav_path\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav_path):\n",
        "        \"\"\"Load the signal, and pass it and its length to the corruption class.\n",
        "        This is done on the CPU in the `collate_fn`.\"\"\"\n",
        "        sig, fs = torchaudio.load(wav_path)\n",
        "\n",
        "        # Resampling\n",
        "        sig = torchaudio.functional.resample(sig, fs, 16000).squeeze(0)\n",
        "        return sig\n",
        "\n",
        "    # Define label pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"num_speakers\")\n",
        "    @sb.utils.data_pipeline.provides(\"num_speakers\", \"num_speakers_encoded\")\n",
        "    def label_pipeline(num_speakers):\n",
        "        \"\"\"Defines the pipeline to process the spk labels.\n",
        "        Note that we have to assign a different integer to each class\n",
        "        through the label encoder.\n",
        "        \"\"\"\n",
        "        yield num_speakers\n",
        "        num_speakers_encoded = label_encoder.encode_label_torch(num_speakers)\n",
        "        yield num_speakers_encoded\n",
        "\n",
        "    # Define datasets. We also connect the dataset with the data processing\n",
        "    # functions defined above.\n",
        "    datasets = {}\n",
        "    data_info = {\n",
        "        \"train\": hparams[\"train_annotation\"],\n",
        "        \"valid\": hparams[\"valid_annotation\"],\n",
        "        \"test\": hparams[\"test_annotation\"],\n",
        "    }\n",
        "    hparams[\"dataloader_options\"][\"shuffle\"] = True\n",
        "    for dataset in data_info:\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
        "            json_path=data_info[dataset],\n",
        "            dynamic_items=[audio_pipeline, label_pipeline],\n",
        "            output_keys=[\"id\", \"sig\", \"num_speakers_encoded\"],\n",
        "        )\n",
        "\n",
        "    # Load or compute the label encoder (with multi-GPU DDP support)\n",
        "    # Please, take a look into the lab_enc_file to see the label to index\n",
        "    # mapping.\n",
        "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
        "    label_encoder.load_or_create(\n",
        "        path=lab_enc_file,\n",
        "        from_didatasets=[datasets[\"train\"]],\n",
        "        output_key=\"num_speakers\",\n",
        "    )\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "# Recipe begins!\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Reading command line arguments.\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "\n",
        "    # Load hyperparameters file with command-line overrides.\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin,  overrides)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # Create dataset objects \"train\", \"valid\", and \"test\".\n",
        "    datasets = dataio_prep(hparams)\n",
        "\n",
        "    # Initialize the Brain object to prepare for mask training.\n",
        "    digit_brain = DigitBrain(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"opt_class\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    # The `fit()` method iterates the training loop, calling the methods\n",
        "    # necessary to update the parameters of the model. Since all objects\n",
        "    # with changing state are managed by the Checkpointer, training can be\n",
        "    # stopped at any point, and will be resumed on next call.\n",
        "    digit_brain.fit(\n",
        "        epoch_counter=digit_brain.hparams.epoch_counter,\n",
        "        train_set=datasets[\"train\"],\n",
        "        valid_set=datasets[\"valid\"],\n",
        "        train_loader_kwargs=hparams[\"dataloader_options\"],\n",
        "        valid_loader_kwargs=hparams[\"dataloader_options\"],\n",
        "    )\n",
        "\n",
        "    # Load the best checkpoint for evaluation\n",
        "    test_stats = digit_brain.evaluate(\n",
        "        test_set=datasets[\"test\"],\n",
        "        min_key=\"error\",\n",
        "        test_loader_kwargs=hparams[\"dataloader_options\"],\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdOAnZaDeQ3z",
        "outputId": "eb324be2-561f-4cc2-fa1b-57a13c8e34c2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py hparams_xvector_fbanks.yaml --device=\"cuda\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upckNjLwgZfC",
        "outputId": "f35db8da-b347-4d47-a89c-5b09ca0ce231"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-20 20:49:08.936126: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 20:49:08.936204: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 20:49:08.938019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 20:49:10.890341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: /content/results/TIMIT_tiny/Xvector/FBanks/1986\n",
            "<speechbrain.dataio.encoder.CategoricalEncoder object at 0x7ee222623fd0>\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - 146.9k trainable parameters in DigitBrain\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from /content/results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-03-20+20-42-38+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from /content/results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-03-20+20-40-23+00\n",
            "100% 3/3 [00:00<00:00,  3.92it/s]\n",
            "speechbrain.utils.train_logger - Epoch loaded: 1 - test loss: 1.59, test error: 6.65e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "p8OcxYSEiLFR",
        "outputId": "99339bce-b330-494e-c214-399fc1da25a1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYSSxVIYm7XD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tv7r-HkNnlPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}