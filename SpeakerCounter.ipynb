{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:10:25.750591Z",
     "start_time": "2024-03-20T05:10:22.938457Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import json\n",
    "import speechbrain as sb\n",
    "import os, sys\n",
    "from speechbrain.utils.data_utils import get_all_files\n",
    "import torch\n",
    "from speechbrain.dataio.dataio import read_audio\n",
    "import random\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecf41c1113f92a8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:10:25.781591Z",
     "start_time": "2024-03-20T05:10:25.751584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7110561b1285e9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T18:15:24.942367Z",
     "start_time": "2024-03-17T18:15:24.935361Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_all_json_data(json_info, file_name=\"train\"):\n",
    "#     data = {}\n",
    "#     for sess_file in json_info:\n",
    "#         if sess_file.endswith('.json'):\n",
    "#             wav_path = sess_file.replace('_metadata.json', '_mixture.wav')\n",
    "#             \n",
    "#             with open(sess_file) as f:\n",
    "#                 session_data = json.load(f)  \n",
    "#                 \n",
    "#             sess_id = os.path.basename(sess_file).split('_')[:-1]\n",
    "#             sess_id = '_'.join(sess_id)\n",
    "# \n",
    "#             item_data = {\n",
    "#                 \"wav_path\": wav_path,\n",
    "#                 \"num_speakers\": f\"{session_data.get('num_speakers',sess_id.split('_')[-1])}\",\n",
    "#             }\n",
    "#             # \n",
    "#             # for key, value in session_data.items():\n",
    "#             #     if key != 'num_speakers':\n",
    "#             #         item_data[key] = value\n",
    "#             \n",
    "#             # Assign the aggregated data to this session ID\n",
    "#             data[sess_id] = item_data\n",
    "#     \n",
    "#     # Save combined metadata to JSON\n",
    "#     metadata_path = os.path.join(f\"{file_name}_data.json\")\n",
    "#     with open(metadata_path, \"w\") as jsonfile:\n",
    "#         json.dump(data, jsonfile, indent=4)\n",
    "#         \n",
    "# # train_json_info = get_all_files(\"./maindata/train\", match_and=['.json'])\n",
    "# # dev_json_info = get_all_files(\"./maindata/dev\", match_and=['.json'])\n",
    "# # eval_json_info = get_all_files(\"./maindata/eval\", match_and=['.json'])\n",
    "# # \n",
    "# # get_all_json_data(train_json_info, file_name = \"train\")\n",
    "# # get_all_json_data(dev_json_info, file_name = \"dev\")\n",
    "# # get_all_json_data(eval_json_info, file_name = \"eval\")\n",
    "# # print(\"Gathered all json data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61619761f9798a1c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:11:45.709248Z",
     "start_time": "2024-03-20T05:10:34.505772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.17077106011849916s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0529942512512207s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.07211685180664062s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 262 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0461881160736084s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 502 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.06700611114501953s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=-1)]: Done 687 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1040 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.07312631607055664s.) Setting batch_size=64.\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2336 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.08956098556518555s.) Setting batch_size=128.\n",
      "[Parallel(n_jobs=-1)]: Done 3712 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 5760 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 9216 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 12928 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 16640 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 20608 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 24576 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 28800 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 33024 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 37504 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 41984 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 46720 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 51456 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 56448 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 61440 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 66688 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 71936 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 77440 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 82944 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 88704 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 94464 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100480 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 106496 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 112768 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 119040 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 125568 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 132096 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 138880 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.19889250216685342s.) Setting batch_size=256.\n",
      "[Parallel(n_jobs=-1)]: Done 145664 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154368 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168448 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 183040 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 197632 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 212736 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 227840 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 243456 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 259072 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 275200 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 291328 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 307968 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 314360 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 316140 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 317290 out of 317290 | elapsed:   20.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.018000364303588867s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.04899287223815918s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.034151315689086914s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.033000946044921875s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.04200482368469238s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.04911327362060547s.) Setting batch_size=64.\n",
      "[Parallel(n_jobs=-1)]: Done 1304 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.07920289039611816s.) Setting batch_size=128.\n",
      "[Parallel(n_jobs=-1)]: Done 3032 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4632 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.17458462715148926s.) Setting batch_size=256.\n",
      "[Parallel(n_jobs=-1)]: Done 7384 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 11480 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 18392 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 25816 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 33240 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 41176 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 49112 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 56560 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 58008 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 61718 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 61928 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 62150 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 62372 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 62618 out of 62657 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 62657 out of 62657 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.011999130249023438s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.05702972412109375s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.04219555854797363s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.04763054847717285s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.059612274169921875s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.06082653999328613s.) Setting batch_size=64.\n",
      "[Parallel(n_jobs=-1)]: Done 1304 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.08888888359069824s.) Setting batch_size=128.\n",
      "[Parallel(n_jobs=-1)]: Done 3032 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4632 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.15979599952697754s.) Setting batch_size=256.\n",
      "[Parallel(n_jobs=-1)]: Done 7384 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 11480 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 18392 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 25816 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 33240 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 41176 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 49112 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 56568 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 59312 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 61824 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 62104 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 62400 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 62696 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 63080 out of 63080 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_file(path):\n",
    "    # Optimized path operations\n",
    "    parts = path.split(\"/\")[-1].split(\"\\\\\")[-1].split(\"_\")\n",
    "    id = \"_\".join(parts[:-1])\n",
    "    num_speakers = parts[3]\n",
    "    info = torchaudio.info(path)\n",
    "    length = info.num_frames / 16000\n",
    "\n",
    "    return id, {\n",
    "        \"wav_path\": path.replace(\"\\\\\",\"/\"),\n",
    "        \"num_speakers\": num_speakers,\n",
    "        \"length\": length\n",
    "    }\n",
    "\n",
    "def load_json(json_paths, save_file=\"train\"):\n",
    "    data = {}\n",
    "\n",
    "    # Parallel processing\n",
    "    results = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(process_file)(path) for path in json_paths\n",
    "    )\n",
    "\n",
    "    for id, path_data in results:\n",
    "        data[id] = path_data\n",
    "\n",
    "    with open(f\"./maindata/{save_file}_data.json\", 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "train_files = get_all_files(\"./maindata/train\", match_and=['_segment.wav'])\n",
    "test_files = get_all_files(\"./maindata/dev\", match_and=['_segment.wav'])\n",
    "valid_files = get_all_files(\"./maindata/eval\", match_and=['_segment.wav'])\n",
    "\n",
    "load_json(train_files, save_file=\"train\")\n",
    "load_json(test_files, save_file=\"test\")\n",
    "load_json(valid_files, save_file=\"valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%file hparams_ecapa.yaml\n",
    "# \n",
    "# \n",
    "# seed: 1234\n",
    "# __set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
    "# \n",
    "# output_folder: !ref ./results/TIMIT_tiny/Xvector/FBanks/<seed>\n",
    "# save_folder: !ref <output_folder>/save\n",
    "# train_log: !ref <output_folder>/train_log.txt\n",
    "# \n",
    "# # Spectral feature parameters\n",
    "# n_mels: 80\n",
    "# \n",
    "# # left_frames: 0\n",
    "# # right_frames: 0\n",
    "# # deltas: False\n",
    "# \n",
    "# # ECAPA-TDNN model\n",
    "# emb_dim: 192\n",
    "# emb_channels: [1024, 1024, 1024, 1024, 3072]\n",
    "# emb_attention_channels: 128\n",
    "# emb_lin_neurons: 192\n",
    "# batch_size: 512\n",
    "# sampling_rate: 16000\n",
    "# \n",
    "# use_tacotron2_mel_spec: True\n",
    "# \n",
    "# compute_features: !name:speechbrain.lobes.models.Tacotron2.mel_spectogram\n",
    "#     sample_rate: !ref <sample_rate>\n",
    "#     hop_length: !ref <hop_length>\n",
    "#     win_length: !ref <win_length>\n",
    "#     n_fft: !ref <n_fft>\n",
    "#     n_mels: !ref <n_mel_channels>\n",
    "#     f_min: !ref <mel_fmin>\n",
    "#     f_max: !ref <mel_fmax>\n",
    "#     power: !ref <power>\n",
    "#     normalized: !ref <mel_normalized>\n",
    "#     norm: !ref <norm>\n",
    "#     mel_scale: !ref <mel_scale>\n",
    "#     compression: !ref <dynamic_range_compression>\n",
    "# \n",
    "# mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
    "#     norm_type: global\n",
    "#     std_norm: False\n",
    "# \n",
    "# embedding_model: !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN\n",
    "#     input_size: !ref <n_mel_channels>\n",
    "#     channels: [1024, 1024, 1024, 1024, 3072]\n",
    "#     kernel_sizes: [5, 3, 3, 3, 1]\n",
    "#     dilations: [1, 2, 3, 4, 1]\n",
    "#     groups: [1, 1, 1, 1, 1]\n",
    "#     attention_channels: 128\n",
    "#     lin_neurons: 192\n",
    "# \n",
    "# \n",
    "# classifier: !new:speechbrain.lobes.models.ECAPA_TDNN.Classifier\n",
    "#     input_size: 192\n",
    "#     out_neurons: !ref <out_n_neurons>\n",
    "# \n",
    "# epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "#     limit: !ref <number_of_epochs>\n",
    "# \n",
    "# modules:\n",
    "#     compute_features: !ref <compute_features>\n",
    "#     mean_var_norm: !ref <mean_var_norm>\n",
    "#     embedding_model: !ref <embedding_model>\n",
    "#     classifier: !ref <classifier>\n",
    "# \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T18:48:38.750733Z",
     "start_time": "2024-03-18T18:48:38.735727Z"
    }
   },
   "id": "8196413f13fb34a1",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d658ae9f4f6bb52",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:15:53.860685Z",
     "start_time": "2024-03-20T05:15:53.835695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hparams_xvector_fbanks.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file hparams_xvector_fbanks.yaml\n",
    "\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "seed: 1986\n",
    "__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]\n",
    "\n",
    "output_folder: !ref ./results/TIMIT_tiny/Xvector/FBanks/<seed>\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# Path where data manifest files are stored\n",
    "data_dir: ./maindata\n",
    "train_annotation: !ref <data_dir>/train_data.json\n",
    "valid_annotation: !ref <data_dir>/valid_data.json\n",
    "test_annotation: !ref <data_dir>/test_data.json\n",
    "\n",
    "# The train logger writes training statistics to a file, as well as stdout.\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n",
    "        \n",
    "# Feature parameters\n",
    "n_mels: 40\n",
    "deltas: True\n",
    "\n",
    "# Training Parameters\n",
    "sample_rate: 16000\n",
    "number_of_epochs: 100\n",
    "batch_size: 64\n",
    "# lr_start: 0.001\n",
    "# lr_final: 0.0001\n",
    "# lr_dont_halve_until_epoch: 80\n",
    "# lr_patience: 1\n",
    "n_classes: 5\n",
    "emb_dim: 64 # dimensionality of the embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataloader_options:\n",
    "    batch_size: !ref <batch_size>\n",
    "\n",
    "# Feature extraction\n",
    "compute_features: !new:speechbrain.lobes.features.Fbank\n",
    "    n_mels: !ref <n_mels>\n",
    "    # deltas: !ref <deltas>\n",
    "\n",
    "# Mean and std normalization of the input features\n",
    "mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
    "    norm_type: global\n",
    "\n",
    "# Embedding model: from variable size digits gets a fixed size embedding vector\n",
    "embedding_model: !new:speechbrain.lobes.models.Xvector.Xvector\n",
    "    in_channels: !ref <n_mels>\n",
    "    activation: !name:torch.nn.LeakyReLU\n",
    "    tdnn_blocks: 5\n",
    "    tdnn_channels: [64, 64, 64, 64, 512]\n",
    "    tdnn_kernel_sizes: [5, 3, 3, 1, 1]\n",
    "    tdnn_dilations: [1, 2, 3, 1, 1]\n",
    "    lin_neurons: !ref <emb_dim>\n",
    "\n",
    "# Clasifier applied on top of the embeddings\n",
    "classifier: !new:speechbrain.lobes.models.Xvector.Classifier\n",
    "    input_shape: [null, null, !ref <emb_dim>]\n",
    "    activation: !name:torch.nn.LeakyReLU\n",
    "    lin_blocks: 1\n",
    "    lin_neurons: !ref <emb_dim>\n",
    "    out_neurons: !ref <n_classes>\n",
    "\n",
    "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
    "# which is saved by the Checkpointer so that training can be resumed\n",
    "# if it gets interrupted at any point.\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <number_of_epochs>\n",
    "\n",
    "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
    "# device, as well as having train()/eval() called on them by the Brain class.\n",
    "modules:\n",
    "    compute_features: !ref <compute_features>\n",
    "    mean_var_norm: !ref <mean_var_norm>\n",
    "    embedding_model: !ref <embedding_model>\n",
    "    classifier: !ref <classifier>\n",
    "\n",
    "# This optimizer will be constructed by the Brain class after all parameters\n",
    "# are moved to the correct device. Then it will be added to the checkpointer.\n",
    "# \n",
    "# opt_class: !name:torch.optim.Adadelta\n",
    "#     lr: !ref <lr>\n",
    "#     rho: 0.95\n",
    "#     eps: 1.e-8\n",
    "\n",
    "\n",
    "opt_class: !name:torch.optim.Adam\n",
    "    lr: 0.001\n",
    "    weight_decay: 0.00002\n",
    "\n",
    "# This function manages learning rate annealing over the epochs.\n",
    "# We here use the simple lr annealing method that linearly decreases\n",
    "# the lr from the initial value to the final one.\n",
    "\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
    "    mode: triangular2\n",
    "    gamma: 0.9998\n",
    "    base_lr: 0.001 #best for adam\n",
    "    max_lr: 0.004 #hope that it escapes local minima\n",
    "    step_size: 9935 #317920/64 = 4967.5 *2-8 == 9935-39740\n",
    "\n",
    "\n",
    "\n",
    "# lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
    "#    initial_value: !ref <lr_start>\n",
    "#    final_value: !ref <lr_final>\n",
    "#    epoch_count: !ref <number_of_epochs>\n",
    "\n",
    "# \n",
    "# lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
    "#     initial_value: !ref <lr>\n",
    "#     improvement_threshold: 0.0025\n",
    "#     annealing_factor: 0.8\n",
    "#     patient: 0\n",
    "\n",
    "# lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "#     lr_min: !ref <lr_final>\n",
    "#     dont_halve_until_epoch: !ref <lr_dont_halve_until_epoch>\n",
    "#     patience: !ref <lr_patience>\n",
    "\n",
    "# lr_annealing_model_3: !new:speechbrain.nnet.schedulers.CyclicCosineScheduler\n",
    "#   lr_initial: !ref <peak_lr>\n",
    "#   n_warmup_steps: !ref <warmup_steps>\n",
    "#   total_steps: !ref <total_step>\n",
    "\n",
    "\n",
    "\n",
    "# This object is used for saving the state of training both so that it\n",
    "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
    "# can be later loaded for evaluation or inference.\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        embedding_model: !ref <embedding_model>\n",
    "        classifier: !ref <classifier>\n",
    "        normalizer: !ref <mean_var_norm>\n",
    "        counter: !ref <epoch_counter>\n",
    "        lr_annealing: !ref <lr_annealing>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797544aef49abdf7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:15:54.913256Z",
     "start_time": "2024-03-20T05:15:54.892238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%file train.py\n",
    "# Your code here\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"Recipe for training a spk classification system.\"\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "\n",
    "# Brain class for speech enhancement training\n",
    "class DigitBrain(sb.Brain):\n",
    "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
    "\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"Runs all the computations that transforms the input into the\n",
    "        output probabilities over the N classes.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : Tensor\n",
    "            Tensor that contains the posterior probabilities over the N classes.\n",
    "        \"\"\"\n",
    "        # Your code here. Aim for 7-8 lines\n",
    "        batch = batch.to(self.device)\n",
    "        wavs, lens = batch.sig\n",
    "        feats = self.modules.compute_features(wavs)\n",
    "        feats = self.modules.mean_var_norm(feats, lens)\n",
    "        embeddings = self.modules.embedding_model(feats, lens)\n",
    "        predictions = self.modules.classifier(embeddings)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        predictions : tensor\n",
    "            The output tensor from `compute_forward`.\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.Tensor\n",
    "            A one-element tensor used for backpropagating the gradient.\n",
    "        \"\"\"\n",
    "\n",
    "        # Your code here. Aim for 7-8 lines\n",
    "        _, lens = batch['sig']\n",
    "        num_speakers_encoded = batch[\"num_speakers_encoded\"].data\n",
    "\n",
    "        loss = sb.nnet.losses.nll_loss(predictions, num_speakers_encoded, lens)\n",
    "        self.loss_metric.append(\n",
    "            batch.id, predictions, num_speakers_encoded, lens, reduction=\"batch\"\n",
    "        )\n",
    "\n",
    "        # Compute classification error at test time\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            if hasattr(self.hparams.lr_annealing, \"on_batch_end\"):\n",
    "                self.hparams.lr_annealing.on_batch_end(self.optimizer)\n",
    "            self.error_metrics.append(batch.id, predictions, num_speakers_encoded, lens)\n",
    "        return loss\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"Gets called at the beginning of each epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up statistics trackers for this stage\n",
    "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
    "            metric=sb.nnet.losses.nll_loss\n",
    "        )\n",
    "\n",
    "        # Set up evaluation-only statistics trackers\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
    "        \"\"\"Gets called at the end of an epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
    "        stage_loss : float\n",
    "            The average loss for all of the data processed in this stage.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store the train loss until the validation stage.\n",
    "        if stage == sb.Stage.TRAIN:              \n",
    "            self.train_loss = stage_loss\n",
    "\n",
    "        # Summarize the statistics from the stage for record-keeping.\n",
    "        else:\n",
    "            stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"error\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        # At the end of validation...\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # if isinstance(\n",
    "            #     self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            # ):\n",
    "            #     current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "            #         [self.optimizer], epoch, stage_loss\n",
    "            #     )\n",
    "            #     sb.nnet.schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            # elif isinstance(\n",
    "            #         self.hparams.lr_annealing,\n",
    "            #         sb.nnet.schedulers.CyclicCosineScheduler,\n",
    "            #     ):\n",
    "            #     current_lr, next_lr = self.hparams.lr_annealing(stage_loss)\n",
    "            #     sb.nnet.schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            #     \n",
    "            # else:\n",
    "            #     current_lr, next_lr = self.hparams.lr_annealing(epoch)\n",
    "            #     sb.nnet.schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            \n",
    "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
    "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
    "\n",
    "            # The train_logger writes a summary to stdout and to the logfile.\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch\": epoch, \"lr\": old_lr},\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats=stats,\n",
    "            )\n",
    "\n",
    "            # Save the current checkpoint and delete previous checkpoints,\n",
    "            self.checkpointer.save_and_keep_only(meta=stats, min_keys=[\"error\"])\n",
    "\n",
    "        # We also write statistics about test data to stdout and to the logfile.\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stats,\n",
    "            )\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
    "    It also defines the data processing pipeline through user-defined functions.\n",
    "    We expect `prepare_mini_librispeech` to have been called before this,\n",
    "    so that the `train.json`, `valid.json`,  and `valid.json` manifest files\n",
    "    are available.\n",
    "    Arguments\n",
    "    ---------\n",
    "    hparams : dict\n",
    "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
    "        all the hyperparameters needed for dataset construction and loading.\n",
    "    Returns\n",
    "    -------\n",
    "    datasets : dict\n",
    "        Contains two keys, \"train\" and \"valid\" that correspond\n",
    "        to the appropriate DynamicItemDataset object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization of the label encoder. The label encoder assigns to each\n",
    "    # of the observed label a unique index (e.g, 'digit0': 0, 'digit1': 1, ..)\n",
    "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
    "    print(label_encoder)\n",
    "\n",
    "    # Define audio pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"wav_path\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav_path):\n",
    "        \"\"\"Load the signal, and pass it and its length to the corruption class.\n",
    "        This is done on the CPU in the `collate_fn`.\"\"\"\n",
    "        sig, fs = torchaudio.load(wav_path)\n",
    "\n",
    "        # Resampling\n",
    "        sig = torchaudio.functional.resample(sig, fs, 16000).squeeze(0)\n",
    "        return sig\n",
    "\n",
    "    # Define label pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"num_speakers\")\n",
    "    @sb.utils.data_pipeline.provides(\"num_speakers\", \"num_speakers_encoded\")\n",
    "    def label_pipeline(num_speakers):\n",
    "        \"\"\"Defines the pipeline to process the spk labels.\n",
    "        Note that we have to assign a different integer to each class\n",
    "        through the label encoder.\n",
    "        \"\"\"\n",
    "        yield num_speakers\n",
    "        num_speakers_encoded = label_encoder.encode_label_torch(num_speakers)\n",
    "        yield num_speakers_encoded\n",
    "\n",
    "    # Define datasets. We also connect the dataset with the data processing\n",
    "    # functions defined above.\n",
    "    datasets = {}\n",
    "    data_info = {\n",
    "        \"train\": hparams[\"train_annotation\"],\n",
    "        \"valid\": hparams[\"valid_annotation\"],\n",
    "        \"test\": hparams[\"test_annotation\"],\n",
    "    }\n",
    "    hparams[\"dataloader_options\"][\"shuffle\"] = True\n",
    "    for dataset in data_info:\n",
    "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
    "            json_path=data_info[dataset],\n",
    "            dynamic_items=[audio_pipeline, label_pipeline],\n",
    "            output_keys=[\"id\", \"sig\", \"num_speakers_encoded\"],\n",
    "        )\n",
    "\n",
    "    # Load or compute the label encoder (with multi-GPU DDP support)\n",
    "    # Please, take a look into the lab_enc_file to see the label to index\n",
    "    # mapping.\n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[datasets[\"train\"]],\n",
    "        output_key=\"num_speakers\",\n",
    "    )\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "# Recipe begins!\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Reading command line arguments.\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "\n",
    "    # Load hyperparameters file with command-line overrides.\n",
    "    with open(hparams_file) as fin:\n",
    "        hparams = load_hyperpyyaml(fin,  overrides)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Create dataset objects \"train\", \"valid\", and \"test\".\n",
    "    datasets = dataio_prep(hparams)\n",
    "\n",
    "    # Initialize the Brain object to prepare for mask training.\n",
    "    digit_brain = DigitBrain(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"opt_class\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "    # The `fit()` method iterates the training loop, calling the methods\n",
    "    # necessary to update the parameters of the model. Since all objects\n",
    "    # with changing state are managed by the Checkpointer, training can be\n",
    "    # stopped at any point, and will be resumed on next call.\n",
    "    digit_brain.fit(\n",
    "        epoch_counter=digit_brain.hparams.epoch_counter,\n",
    "        train_set=datasets[\"train\"],\n",
    "        valid_set=datasets[\"valid\"],\n",
    "        train_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    )\n",
    "\n",
    "    # Load the best checkpoint for evaluation\n",
    "    test_stats = digit_brain.evaluate(\n",
    "        test_set=datasets[\"test\"],\n",
    "        min_key=\"error\",\n",
    "        test_loader_kwargs=hparams[\"dataloader_options\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5daa9fcf95f355d0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:15:56.121071Z",
     "start_time": "2024-03-20T05:15:56.087015Z"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -rf results/train\n",
    "\n",
    "# Run Training\n",
    "torch.cuda.set_device('cuda:0')\n",
    "# !python train.py hparams_xvector_fbanks.yaml"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# !python train.py hparams_xvector_fbanks.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T19:45:45.557315Z",
     "start_time": "2024-03-18T19:45:45.543320Z"
    }
   },
   "id": "f2099204ff86baa4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "57bb9fe07136d2bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
