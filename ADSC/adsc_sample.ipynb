{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-13T23:59:24.798172Z",
     "start_time": "2024-03-13T23:59:22.157038Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import json\n",
    "import speechbrain as sb\n",
    "import os, sys\n",
    "from speechbrain.utils.data_utils import get_all_files\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_all_json_data(json_info, file_name=\"train\"):\n",
    "    data = {}\n",
    "    for sess in json_info:\n",
    "        if sess.endswith('.json'):\n",
    "            wav_path = sess.replace('_metadata.json', '_mixture.wav')\n",
    "        \n",
    "            with open(sess) as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            json_data['wav_path'] = wav_path\n",
    "            \n",
    "            sess_id = os.path.basename(sess).split('_')[:-1] \n",
    "            sess_id = '_'.join(sess_id)\n",
    "            \n",
    "            json_data['num_speakers'] = sess_id.split(\"_\")[-1]\n",
    "            if sess_id not in data:\n",
    "                data[sess_id] = []\n",
    "            data[sess_id].append(json_data)\n",
    "    \n",
    "    # Save combined metadata to JSON\n",
    "    metadata_path = os.path.join(\"../../data\", f\"{file_name}_data.json\")\n",
    "    with open(metadata_path, \"w\") as jsonfile:\n",
    "        json.dump(data, jsonfile, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T23:59:24.814170Z",
     "start_time": "2024-03-13T23:59:24.799162Z"
    }
   },
   "id": "3677f7d824a5902d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered all json data\n"
     ]
    }
   ],
   "source": [
    "train_json_info = get_all_files(\"../../data/train\", match_and=['.json'])\n",
    "dev_json_info = get_all_files(\"../../data/dev\", match_and=['.json'])\n",
    "eval_json_info = get_all_files(\"../../data/eval\", match_and=['.json'])\n",
    "\n",
    "get_all_json_data(train_json_info, file_name = \"train\")\n",
    "get_all_json_data(dev_json_info, file_name = \"dev\")\n",
    "get_all_json_data(eval_json_info, file_name = \"eval\")\n",
    "print(\"Gathered all json data\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T23:59:28.074954Z",
     "start_time": "2024-03-13T23:59:24.815163Z"
    }
   },
   "id": "ed0f99d0d65a98c8",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hparams_crdnn_fbanks.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file hparams_crdnn_fbanks.yaml\n",
    "# Seed and output folders\n",
    "seed: 1986\n",
    "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
    "output_folder: !ref results/ADSC_CRDNN/<seed>\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# LibriParty (main data)\n",
    "data_folder: ../../data/LibriParty  # e.g. /path/to/LibriParty\n",
    "\n",
    "# Openrir Dataset for augmentation\n",
    "data_folder_noise: !ref <data_folder>/noise # The noisy sequencies for data augmentation will automatically be downloaded here.\n",
    "NOISE_DATASET_URL: https://www.dropbox.com/scl/fi/a09pj97s5ifan81dqhi4n/noises.zip?rlkey=j8b0n9kdjdr32o1f06t0cw5b7&dl=1\n",
    "noise_csv_openrir: !ref <save_folder>/noise_openrir.csv #The data manifest files are created by the data preparation script\n",
    "\n",
    "# Additional data (for augmentation)\n",
    "#musan_folder: !PLACEHOLDER  # e.g, /path/to/musan (download it from the web before)\n",
    "#commonlanguage_folder: !PLACEHOLDER  # e.g, /path/to/commonlang (download it from the web before)\n",
    "\n",
    "# Manifest files (created by the data preparation)\n",
    "annotation_train: !ref <save_folder>/train.json\n",
    "annotation_valid: !ref <save_folder>/valid.json\n",
    "annotation_test: !ref <save_folder>/test.json\n",
    "#music_csv: !ref <save_folder>/music.csv\n",
    "noise_csv: !ref <save_folder>/noise.csv\n",
    "#speech_csv: !ref <save_folder>/speech.csv\n",
    "#multilang_speech_csv: !ref <save_folder>/multilang_speech.csv\n",
    "skip_prep: False # Skip data preparation\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "N_epochs: 100\n",
    "lr: 1.0\n",
    "lr_final: 0.1\n",
    "batch_size: 2\n",
    "example_length: 5 # in seconds\n",
    "sample_rate: 16000\n",
    "time_resolution: 0.01 # in seconds\n",
    "\n",
    "num_workers: 4\n",
    "train_dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: !ref <num_workers>\n",
    "valid_dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: !ref <num_workers>\n",
    "test_dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: !ref <num_workers>\n",
    "\n",
    "# Feature parameters\n",
    "n_fft: 400\n",
    "n_mels: 40\n",
    "\n",
    "####################### Model Parameters #######################################\n",
    "# activation: !name:torch.nn.LeakyReLU\n",
    "# dropout: 0.15\n",
    "# cnn_blocks: 2\n",
    "# cnn_channels: (16, 16)\n",
    "# cnn_kernelsize: (3, 3)\n",
    "rnn_layers: 2\n",
    "rnn_neurons: 32\n",
    "# rnn_bidirectional: True\n",
    "# dnn_blocks: 1\n",
    "dnn_neurons: 16\n",
    "output_neurons: 1\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "# Download and prepare the dataset of noisy sequences for augmentation\n",
    "prepare_noise_data: !name:speechbrain.augment.preparation.prepare_dataset_from_URL\n",
    "    URL: !ref <NOISE_DATASET_URL>\n",
    "    dest_folder: !ref <data_folder_noise>\n",
    "    ext: wav\n",
    "    csv_file: !ref <noise_csv_openrir>\n",
    "\n",
    "add_noise: !new:speechbrain.augment.time_domain.AddNoise\n",
    "    csv_file: !ref <noise_csv_openrir>\n",
    "    snr_low: -5\n",
    "    snr_high: 15\n",
    "    noise_sample_rate: 16000\n",
    "    clean_sample_rate: 16000\n",
    "    num_workers: !ref <num_workers>\n",
    "\n",
    "#add_noise_musan: !new:speechbrain.augment.time_domain.AddNoise\n",
    "#    csv_file: !ref <noise_csv>\n",
    "#    snr_low: -5\n",
    "#    snr_high: 15\n",
    "#    noise_sample_rate: 16000\n",
    "#    clean_sample_rate: 16000\n",
    "#    num_workers: !ref <num_workers>\n",
    "#\n",
    "#add_music_musan: !new:speechbrain.augment.time_domain.AddNoise\n",
    "#    csv_file: !ref <music_csv>\n",
    "#    snr_low: -5\n",
    "#    snr_high: 15\n",
    "#    noise_sample_rate: 16000\n",
    "#    clean_sample_rate: 16000\n",
    "#    num_workers: !ref <num_workers>\n",
    "#\n",
    "#add_speech_musan: !new:speechbrain.augment.time_domain.AddNoise\n",
    "#    csv_file: !ref <speech_csv>\n",
    "#    snr_low: -5\n",
    "#    snr_high: 15\n",
    "#    noise_sample_rate: 16000\n",
    "#    clean_sample_rate: 16000\n",
    "#    num_workers: !ref <num_workers>\n",
    "\n",
    "#add_speech_multilang: !new:speechbrain.augment.time_domain.AddNoise\n",
    "#    csv_file: !ref <multilang_speech_csv>\n",
    "#    snr_low: -5\n",
    "#    snr_high: 15\n",
    "#    noise_sample_rate: 16000\n",
    "#    clean_sample_rate: 16000\n",
    "#    num_workers: !ref <num_workers>\n",
    "\n",
    "# Models\n",
    "compute_features: !new:speechbrain.lobes.features.Fbank\n",
    "    sample_rate: !ref <sample_rate>\n",
    "    n_fft: !ref <n_fft>\n",
    "    n_mels: !ref <n_mels>\n",
    "    hop_length: !ref <time_resolution> * 1000 # in ms\n",
    "\n",
    "mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
    "    norm_type: sentence\n",
    "\n",
    "cnn: !new:speechbrain.nnet.containers.Sequential\n",
    "    input_shape: [null, null, !ref <n_mels>]\n",
    "    norm1: !name:speechbrain.nnet.normalization.LayerNorm\n",
    "    cnn1: !name:speechbrain.lobes.models.CRDNN.CNN_Block\n",
    "        channels: 16\n",
    "        kernel_size: (3, 3)\n",
    "    cnn2: !name:speechbrain.lobes.models.CRDNN.CNN_Block\n",
    "        channels: 32\n",
    "        kernel_size: (3, 3)\n",
    "\n",
    "rnn: !new:speechbrain.nnet.RNN.GRU\n",
    "    input_shape: [null, null, 320]\n",
    "    hidden_size: !ref <rnn_neurons>\n",
    "    num_layers: !ref <rnn_layers>\n",
    "    bidirectional: True\n",
    "\n",
    "dnn: !new:speechbrain.nnet.containers.Sequential\n",
    "    input_shape: [null, null, !ref <rnn_neurons> * 2]\n",
    "    dnn1: !name:speechbrain.lobes.models.CRDNN.DNN_Block\n",
    "        neurons: !ref <dnn_neurons>\n",
    "    dnn2: !name:speechbrain.lobes.models.CRDNN.DNN_Block\n",
    "        neurons: !ref <dnn_neurons>\n",
    "    lin: !name:speechbrain.nnet.linear.Linear\n",
    "        n_neurons: !ref <output_neurons>\n",
    "        bias: False\n",
    "\n",
    "\n",
    "model: !new:torch.nn.ModuleList\n",
    "    - [!ref <cnn>, !ref <rnn>, !ref <dnn>]\n",
    "\n",
    "modules:\n",
    "    model: !ref <model>\n",
    "    cnn: !ref <cnn>\n",
    "    rnn: !ref <rnn>\n",
    "    dnn: !ref <dnn>\n",
    "    mean_var_norm: !ref <mean_var_norm>\n",
    "\n",
    "opt_class: !name:torch.optim.Adadelta\n",
    "    lr: !ref <lr>\n",
    "    rho: 0.95\n",
    "    eps: 1.e-8\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
    "    initial_value: !ref <lr>\n",
    "    final_value: !ref <lr_final>\n",
    "    epoch_count: !ref <N_epochs>\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        model: !ref <model>\n",
    "        normalizer: !ref <mean_var_norm>\n",
    "        counter: !ref <epoch_counter>\n",
    "\n",
    "compute_BCE_cost: !name:speechbrain.nnet.losses.bce_loss\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "train_stats: !name:speechbrain.utils.metric_stats.BinaryMetricStats\n",
    "test_stats: !name:speechbrain.utils.metric_stats.BinaryMetricStats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T23:55:33.526555Z",
     "start_time": "2024-03-13T23:55:33.505365Z"
    }
   },
   "id": "7d658ae9f4f6bb52",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%file train.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "797544aef49abdf7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T23:38:41.268847Z",
     "start_time": "2024-03-13T23:38:39.221941Z"
    }
   },
   "id": "5daa9fcf95f355d0",
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
